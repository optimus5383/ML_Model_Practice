{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Mapping' from 'collections' (c:\\Users\\SMEET3080\\anaconda3\\envs\\MIn\\lib\\collections\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32me:\\김진민\\ML\\Gan_ex.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EA%B9%80%EC%A7%84%EB%AF%BC/ML/Gan_ex.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EA%B9%80%EC%A7%84%EB%AF%BC/ML/Gan_ex.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mabc\u001b[39;00m \u001b[39mimport\u001b[39;00m Mapping\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/%EA%B9%80%EC%A7%84%EB%AF%BC/ML/Gan_ex.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpl\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EA%B9%80%EC%A7%84%EB%AF%BC/ML/Gan_ex.ipynb#W0sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m random_seed \u001b[39m=\u001b[39m \u001b[39m42\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EA%B9%80%EC%A7%84%EB%AF%BC/ML/Gan_ex.ipynb#W0sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m torch\u001b[39m.\u001b[39mmanual_seed(random_seed)\n",
      "File \u001b[1;32mc:\\Users\\SMEET3080\\anaconda3\\envs\\MIn\\lib\\site-packages\\pytorch_lightning\\__init__.py:53\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m     sys\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mwrite(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPartial import of `\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m` during the build process.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)  \u001b[39m# pragma: no-cover\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     \u001b[39m# We are not importing the rest of the lightning during the build process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 53\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m LightningModule, data_loader\n\u001b[0;32m     54\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m Callback\n\u001b[0;32m     55\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrainer\u001b[39;00m \u001b[39mimport\u001b[39;00m Trainer\n",
      "File \u001b[1;32mc:\\Users\\SMEET3080\\anaconda3\\envs\\MIn\\lib\\site-packages\\pytorch_lightning\\core\\__init__.py:339\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mA :class:`~LightningModule` organizes your PyTorch code into the following sections:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    336\u001b[0m \n\u001b[0;32m    337\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecorators\u001b[39;00m \u001b[39mimport\u001b[39;00m data_loader\n\u001b[0;32m    340\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlightning\u001b[39;00m \u001b[39mimport\u001b[39;00m LightningModule\n\u001b[0;32m    342\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mLightningModule\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdata_loader\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\SMEET3080\\anaconda3\\envs\\MIn\\lib\\site-packages\\pytorch_lightning\\core\\decorators.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Callable\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlightning\u001b[39;00m \u001b[39mimport\u001b[39;00m LightningModule\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m \u001b[39mimport\u001b[39;00m rank_zero_warn\n\u001b[0;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdata_loader\u001b[39m(fn):\n",
      "File \u001b[1;32mc:\\Users\\SMEET3080\\anaconda3\\envs\\MIn\\lib\\site-packages\\pytorch_lightning\\core\\lightning.py:19\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m \u001b[39mimport\u001b[39;00m _logger \u001b[39mas\u001b[39;00m log\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrads\u001b[39;00m \u001b[39mimport\u001b[39;00m GradInformation\n\u001b[1;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhooks\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelHooks\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmemory\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelSummary\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelIO, PRIMITIVE_TYPES, ALLOWED_CONFIG_TYPES\n",
      "File \u001b[1;32mc:\\Users\\SMEET3080\\anaconda3\\envs\\MIn\\lib\\site-packages\\pytorch_lightning\\core\\hooks.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mimport\u001b[39;00m Module\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizer\u001b[39;00m \u001b[39mimport\u001b[39;00m Optimizer\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m \u001b[39mimport\u001b[39;00m move_data_to_device, NATIVE_AMP_AVALAIBLE\n\u001b[0;32m     10\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mapex\u001b[39;00m \u001b[39mimport\u001b[39;00m amp\n",
      "File \u001b[1;32mc:\\Users\\SMEET3080\\anaconda3\\envs\\MIn\\lib\\site-packages\\pytorch_lightning\\utilities\\__init__.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistributed\u001b[39;00m \u001b[39mimport\u001b[39;00m rank_zero_only, rank_zero_warn, rank_zero_info\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply_func\u001b[39;00m \u001b[39mimport\u001b[39;00m move_data_to_device\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparsing\u001b[39;00m \u001b[39mimport\u001b[39;00m AttributeDict\n\u001b[0;32m     10\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\SMEET3080\\anaconda3\\envs\\MIn\\lib\\site-packages\\pytorch_lightning\\utilities\\apply_func.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mabc\u001b[39;00m \u001b[39mimport\u001b[39;00m ABC\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m Mapping, Sequence\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcopy\u001b[39;00m \u001b[39mimport\u001b[39;00m copy\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, Callable, Union\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Mapping' from 'collections' (c:\\Users\\SMEET3080\\anaconda3\\envs\\MIn\\lib\\collections\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "BATCH_SIZE=128\n",
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "NUM_WORKERS=int(os.cpu_count() / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir=\"./data\", \n",
    "                 batch_size=BATCH_SIZE, num_workers=NUM_WORKERS):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def prepare_data(self):\n",
    "        MNIST(self.data_dir, train=True, download=True)\n",
    "        MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Assign train/val datasets\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "        # Assign test dataset\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=self.batch_size, num_workers=self.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detective: fake or no fake -> 1 output [0, 1]\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Simple CNN\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "  \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        # Flatten the tensor so it can be fed into the FC layers\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Fake Data: output like real data [1, 28, 28] and values -1, 1\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(latent_dim, 7*7*64)  # [n, 256, 7, 7]\n",
    "        self.ct1 = nn.ConvTranspose2d(64, 32, 4, stride=2) # [n, 64, 16, 16]\n",
    "        self.ct2 = nn.ConvTranspose2d(32, 16, 4, stride=2) # [n, 16, 34, 34]\n",
    "        self.conv = nn.Conv2d(16, 1, kernel_size=7)  # [n, 1, 28, 28]\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass latent space input into linear layer and reshape\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 64, 7, 7)  #256\n",
    "        \n",
    "        # Upsample (transposed conv) 16x16 (64 feature maps)\n",
    "        x = self.ct1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Upsample to 34x34 (16 feature maps)\n",
    "        x = self.ct2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Convolution to 28x28 (1 feature map)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jm538\\Desktop\\Code\\ML_study\\Gan_ex.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jm538/Desktop/Code/ML_study/Gan_ex.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mGAN\u001b[39;00m(pl\u001b[39m.\u001b[39mLightningDataModule):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jm538/Desktop/Code/ML_study/Gan_ex.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, latent_dim\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, lr\u001b[39m=\u001b[39m\u001b[39m0.0002\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jm538/Desktop/Code/ML_study/Gan_ex.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pl' is not defined"
     ]
    }
   ],
   "source": [
    "class GAN(pl.LightningDataModule):\n",
    "    def __init__(self, latent_dim=100, lr=0.0002):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.generator = Generator(latent_dim=self.hparams.latent_dim)\n",
    "        self.discriminator = Discriminator()\n",
    "        \n",
    "        \n",
    "        # random noise\n",
    "        \n",
    "        self.validation_z= torch.randn(6, self.hparams.latent_dim)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        return self.generator(z)\n",
    "    \n",
    "    \n",
    "    def adverarial_loss(self, y_hat,y):\n",
    "        return F.binary_cross_entropy(y_hat,y)\n",
    "    \n",
    "    \n",
    "    def training_step(self, batch, batch_dim, optimizer_idx):   \n",
    "        real_imgs, _ = batch\n",
    "        # sample noise\n",
    "        \n",
    "        z= torch.randn(real_imgs.shape[0], self.hparams.latent_dim)\n",
    "        z= z.type_as(real_imgs)\n",
    "        \n",
    "        # train generator : max log(D(G(z)))\n",
    "        \n",
    "        if optimizer_idx==0:\n",
    "            fake_imgs=self(z)\n",
    "            y_hat = self.discriminator(fake_imgs)\n",
    "            \n",
    "            y = torch.ones(real_imgs.size[0], 1)\n",
    "            z= z.type_as(real_imgs)\n",
    "            \n",
    "            g_loss =self.adverarial_loss(y_hat, y)\n",
    "            \n",
    "            log_dict = {\"g_loss\" : g_loss }\n",
    "            return {\"loss\": g_loss, \"progress bar\" : log_dict, \"log\": log_dict}\n",
    "        \n",
    "        # train discriminator : max log(D(x)) + log(1-D(G(z)))\n",
    "                        \n",
    "        if optimizer_idx== 1:\n",
    "            \n",
    "            # how well can it label as real\n",
    "            y_hat_real = self.discriminator(real_imgs)\n",
    "            \n",
    "            y_real = torch.ones(real_imgs.size[0], 1)\n",
    "            \n",
    "            y_real = y_real.type_as(real_imgs)\n",
    "            \n",
    "            real_loss = self.adverarial_loss(y_hat_real, y_real)\n",
    "            \n",
    "            # how well can it label as fake\n",
    "            y_hat_fake =self.discriminator(self(z))\n",
    "            \n",
    "            y_fake = torch.ones(real_imgs.size[0], 1)\n",
    "            y_fake = y_fake.type_as(real_imgs)\n",
    "            \n",
    "            \n",
    "            fake_loss =self.adverarial_loss(y_hat_fake,y_fake)\n",
    "            \n",
    "            d_loss= (real_loss + fake_loss) / 2\n",
    "            \n",
    "            log_dict = {\"d_loss\" : d_loss }\n",
    "            return {\"loss\": d_loss, \"progress bar\" : log_dict, \"log\": log_dict}\n",
    "                \n",
    "    def configure_optimizers(self):\n",
    "        lr=self.hparams.lr\n",
    "        opt_g = torch. optim.Adam(self.generator.parameters(),lr=lr)\n",
    "        opt_d = torch. optim.Adam(self.discriminator.parameters(),lr=lr)\n",
    "        return [opt_g,opt_d], []\n",
    "    \n",
    "    \n",
    "    def plot_imgs(self):\n",
    "        z= self.validation_z.type_as(self.generator.lin1.weight)\n",
    "        sample_imgs=self(z).cpu()\n",
    "        \n",
    "        print('epoch',self.current_epoch)\n",
    "        fig=plt.figure()\n",
    "        \n",
    "        for i in range(sample_imgs.size(0)):\n",
    "            plt.subplot(2,3,i+1)\n",
    "            plt.tight_layout()\n",
    "            plt.imshow(sample_imgs.detach()[i,0,:,:],cmap='gray_r',interpolation='none')\n",
    "            plt.title(\"Generated Data\")\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.axes('off')\n",
    "        plt.show()\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.plot_imgs()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm =MNISTDataModule()\n",
    "\n",
    "model = GAN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer =pl.Trainer(max_epochs=20,Gpus=AVAIL_GPUS)\n",
    "\n",
    "trainer.fit(model,dm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e892409c5dce3d6666d87856a81b57f582cc3442fa2bb89badc9d664ab408af6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
